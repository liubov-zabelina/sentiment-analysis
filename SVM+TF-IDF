import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
import pymorphy2
import re

#0. Настройки
nltk.download("stopwords")
morph = pymorphy2.MorphAnalyzer()
russian_stopwords = set(stopwords.words("russian"))
important_words = {"не", "никогда", "без", "ничего", "никто", "нельзя", "нет", "разве", "ли"}
custom_stopwords = list(russian_stopwords - important_words)

def lemmatize(text):
    tokens = re.findall(r'\b\w+\b', str(text).lower())
    lemmas = [morph.parse(token)[0].normal_form for token in tokens]
    return ' '.join(lemmas)

# === 1. Загрузка и подготовка данных ===
df = pd.read_excel("Obschiy_dataset.xlsx").dropna()
df.columns = ["comment", "sentiment"]
df["comment"] = df["comment"].apply(lemmatize)
df["sentiment"] = df["sentiment"].map({-1: 0, 0: 1, 1: 2})  # 0=негатив, 1=нейтрал, 2=позитив

# Балансировка
max_count = df["sentiment"].value_counts().max()
df = pd.concat([
    df[df["sentiment"] == label].sample(max_count, replace=True, random_state=42)
    for label in df["sentiment"].unique()
]).sample(frac=1, random_state=42).reset_index(drop=True)

#2. Разделение и векторизация
X_train, X_test, y_train, y_test = train_test_split(
    df["comment"], df["sentiment"], test_size=0.2, stratify=df["sentiment"], random_state=42
)

vectorizer = TfidfVectorizer(
    max_features=10000,
    ngram_range=(1, 2),
    stop_words=custom_stopwords
)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)
print(f" Общее количество примеров после оверсемплинга: {len(df)}")

#3. Обучение SVM
svm_model = LinearSVC()
svm_model.fit(X_train_vec, y_train)
y_pred = svm_model.predict(X_test_vec)

#4. Метрики
print("\n Classification Report (SVM):")
print(classification_report(y_test, y_pred, target_names=["негатив", "нейтрал", "позитив"]))
print(f"\n Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f" Macro F1-score: {f1_score(y_test, y_pred, average='macro'):.4f}")

#5. Матрица ошибок
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["негатив", "нейтрал", "позитив"],
            yticklabels=["негатив", "нейтрал", "позитив"])
plt.title("Матрица ошибок SVM")
plt.xlabel("Предсказано")
plt.ylabel("Истинное")
plt.tight_layout()
plt.show()

#6. Общий график топ-слов по классам (с сортировкой внутри классов)
feature_names = np.array(vectorizer.get_feature_names_out())
coefs = svm_model.coef_
top_n = 10
class_labels = ["негатив", "нейтрал", "позитив"]

all_top_words = []
for i, label in enumerate(class_labels):
    top_pos = np.argsort(coefs[i])[::-1][:top_n]
    sorted_pairs = sorted(zip(feature_names[top_pos], coefs[i][top_pos]), key=lambda x: x[1], reverse=True)
    for token, weight in sorted_pairs:
        all_top_words.append({"Токен": token, "Вес": weight, "Класс": label})

top_df = pd.DataFrame(all_top_words)

# Упорядочим отображение так, чтобы строки шли по классам, отсортированным по весу
top_df["Класс"] = pd.Categorical(top_df["Класс"], categories=["негатив", "нейтрал", "позитив"], ordered=True)
top_df.sort_values(by=["Класс", "Вес"], ascending=[True, False], inplace=True)

# График
plt.figure(figsize=(12, 8))
sns.barplot(data=top_df, x="Вес", y="Токен", hue="Класс", dodge=False, palette="Set2")
plt.title("Топ-10 признаков по весу SVM внутри каждого класса", fontsize=14)
plt.xlabel("Вес признака", fontsize=12)
plt.ylabel("Токен", fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.legend(title="Класс", loc="lower right")
plt.grid(axis="x", linestyle="--", alpha=0.4)
plt.tight_layout()
plt.show()
